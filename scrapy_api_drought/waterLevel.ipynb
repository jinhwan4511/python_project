{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4dd552-4263-4d89-8c00-1c0df4e340f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [한국수자원공사] 가뭄 수위관측 openAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c349f01-3d45-4942-8532-6215e2555074",
   "metadata": {},
   "source": [
    "##### 목적 : 수위 측정 관측소별 3개년 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d35b9e-95f5-4f71-bf96-e62d41759037",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용 라이브러리 선언\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode, quote_plus, unquote\n",
    "\n",
    "### 1. XML API 요청을 위한 URL 생성 (openAPI 참조문서의 요청명세를 확인하여 필수 queryString 구성 및 인코딩)\n",
    "## 가뭄 수위관측 openAPI 조회를 위한 queryString 필수 값으로 관측 시설물 코드 리스트 생성\n",
    "facilityCode = pd.read_csv(\"../dataset/facilityCode_1003.csv\")\n",
    "facilityCodeList = facilityCode.cd.tolist()\n",
    "facilityNameList = facilityCode.cdnm.tolist()\n",
    "\n",
    "baseUrl = \"http://apis.data.go.kr/B500001/drghtWlobsOper2/operInfoList2\"\n",
    "currentYear = dt.datetime.now().year\n",
    "yearList = [str(currentYear-3), str(currentYear-2), str(currentYear-1)] # 이전 3개년 검색에 필요한 데이터\n",
    "serviceKey = \"2AlYmSdbDUuKGC0DivNISdLDUqJewAoneYBBTMwCjqcQz8cIiQXSp0je68IfpEVPg6+J2f8OeNy3lak986T1rQ==\"\n",
    "numOfRows = \"9999\"\n",
    "pageNo = \"1\"\n",
    "for i in range (0, len(facilityCodeList)): # 각각의 관측소를 기준으로 데이터프레임을 생성하고자 함\n",
    "    wlobsCd = facilityCodeList[i]\n",
    "    region = facilityNameList[i] # 데이터프레임 csv저장시 사용할 데이터\n",
    "    for j in range(0, len(yearList)):\n",
    "        year = yearList[j]\n",
    "        queryParam2 = '?' + urlencode(\n",
    "            {\n",
    "                quote_plus('serviceKey') : serviceKey, \n",
    "                quote_plus('numOfRows') : numOfRows, # 한 페이지에 노출되는 결과 값 (관측소에서 일일 데이터 측정, 따라서 연간 최대 365개)\n",
    "                quote_plus('pageNo') : pageNo, \n",
    "                quote_plus('wlobsCd') : wlobsCd, # 관측소코드 값\n",
    "                quote_plus('stDt') : year + \"0101\", \n",
    "                quote_plus('edDt') : year + \"1231\"\n",
    "            }\n",
    "        )\n",
    "        obsTargetUrl = baseUrl + queryParam2 \n",
    "\n",
    "        \n",
    "        ### 2. XML API 요청 및 응답받기(BeautifulSoup으로 편집)\n",
    "        resp = requests.get(obsTargetUrl)\n",
    "        resp.encoding = \"utf-8\"\n",
    "        xml = resp.text\n",
    "        bsXml = BeautifulSoup(xml, \"lxml-xml\")\n",
    "        \n",
    "        ### 3. DataFrame으로 만들 필요한 데이터 수집\n",
    "        ## 3-1.\n",
    "        rows = bsXml.findAll(name = \"item\")\n",
    "\n",
    "        ## 사용할 List 선언\n",
    "        rowList = [] # 전체 행을 담을 리스트(DataFrame 생성시 사용)\n",
    "        columnList = [] # 각 행의 컬럼값을 담을 리스트\n",
    "        nameList = [\"flux\", \"obsrdate\", \"wal\", \"wlobscd\", \"wlobsnm\"]\n",
    "\n",
    "        ### 3-2. 행별 컬럼값을 추출\n",
    "        for k in range(0, len(rows)):\n",
    "            ## 주의 : item태그의 자식태그 개수가 생성할 DataFrame의 컬럼개수와 다른 경우 발생. 따라서 DataFrame 생성시, 컬럼값과 컬럼명이 매치되지 않는 상황 발생\n",
    "            columns = rows[k].findAll() \n",
    "            if (len(columns) != len(nameList)): # item태그의 자식태그 개수가 생성할 DataFrame의 컬럼 개수와 다르면 columns 재정의\n",
    "                newColumns = [] # 생성할 DataFrame의 컬럼명을 기준으로 columns를 재정의할 리스트\n",
    "                \n",
    "                # 생성할 dataframe의 컬럼명을 기준으로 자식태그와 비교하여 같은 값 찾기 \n",
    "                for n in range (0, len(nameList)):\n",
    "                    for m in range (0, len(columns)):\n",
    "                        if(nameList[n] == columns[m].name):  \n",
    "                            newColumns.append(columns[m])\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "                    if (len(newColumns) == n): # DataFrame 컬럼명에 맞는 태그가 없는 경우에 None처리해서 값 만들어 넣기\n",
    "                        newColumns.append(None)\n",
    "                    else:\n",
    "                        continue\n",
    "                columns = newColumns \n",
    "                \n",
    "            else: # columns의 개수가 생성할 dataframe의 컬럼 개수와 같으면, 재정의 하지않고 그대로 columns 사용\n",
    "                pass\n",
    "            \n",
    "            for l in range(0, len(columns)):\n",
    "                if (columns[l] == None):\n",
    "                    columnList.append(None)\n",
    "                else:\n",
    "                    columnList.append(columns[l].text) \n",
    "                    \n",
    "            rowList.append(columnList)\n",
    "            columnList = []\n",
    "\n",
    "        ### 4. 행값과 컬럼명을 사용하여 DataFrame 생성 및 csv저장\n",
    "        waterLevelInfoDf = pd.DataFrame(rowList, columns = nameList)\n",
    "        waterLevelInfoDf.to_csv((\"../dataset/waterLevel/waterLevelInfoDf_{}_{}_{}.csv\".format(wlobsCd, region, year)), index = False, encoding = \"ms949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ede334-0216-45ae-a737-5fcb03e18852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
